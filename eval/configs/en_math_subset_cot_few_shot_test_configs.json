{
    "gsm8k-cot": {
        "test_path": "datasets/gsm8k/test.jsonl",
        "language": "en",
        "tasks": [
            "cot"
        ],
        "process_fn": "process_gsm8k_test",
        "answer_extraction_fn": "extract_gsm_few_shot_cot_answer",
        "eval_fn": "eval_last_single_answer",
        "few_shot_prompt": "CoTGSMPrompt"
    },
    "math-cot": {
        "test_path": "datasets/math/test.jsonl",
        "language": "en",
        "tasks": [
            "cot"
        ],
        "process_fn": "process_math_test",
        "answer_extraction_fn": "extract_math_few_shot_cot_answer",
        "eval_fn": "eval_math",
        "few_shot_prompt": "MinervaMathPrompt"
    },
    "amc-cot": {
        "test_path": "datasets/amc23/test.jsonl",
        "language": "en",
        "tasks": [
            "cot"
        ],
        "process_fn": "process_amc",
        "answer_extraction_fn": "extract_gsm_few_shot_cot_answer",
        "eval_fn": "eval_last_single_answer",
        "few_shot_prompt": "CoTAMCPrompt"
    },
    "math_sat-cot": {
        "test_path": "datasets/sat/test.jsonl",
        "language": "en",
        "tasks": [
            "cot"
        ],
        "process_fn": "process_math_sat",
        "answer_extraction_fn": "extract_sat_few_shot_answer",
        "eval_fn": "eval_math_sat",
        "few_shot_prompt": "CoTSATPrompt"
    },
    "mathqa-cot": {
        "test_path": "datasets/mathqa/test.jsonl",
        "language": "en",
        "tasks": [
            "cot"
        ],
        "process_fn": "process_mathqa",
        "answer_extraction_fn": "extract_mathqa_few_shot_answer",
        "eval_fn": "eval_mathqa",
        "few_shot_prompt": "CoTMathQAPrompt"
    }  
}
